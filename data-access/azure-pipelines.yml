# Node.js Function App to Linux on Azure
# Build a Node.js function app and deploy it to Azure as a Linux function app.
# Add steps that analyze code, save build artifacts, deploy, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/javascript

trigger:
 paths:
   include:
     - data-access
 branches:
   include:
     - main

pr:
  branches:
    include:
      - main
  
variables:

  # Function app name
  functionAppName: 'data-access'
 
  # Environment name
  environmentName: 'data-access'
 
  # Agent VM image name
  vmImageName: 'ubuntu-latest'

  system.debug: true

stages:
- stage: Build
  displayName: Build stage
  jobs:  
  - job: Build
    displayName: Build
    pool:
      vmImage: $(vmImageName)
      
    steps:
    - task: NodeTool@0
      inputs:
        versionSpec: '12.x'
      displayName: 'Install Node.js'



    - task: FuncToolsInstaller@0
      inputs:
        version: '3.0.2931'

    - script: |
        if [ -f extensions.csproj ]
        then
            dotnet build extensions.csproj --runtime ubuntu.16.04-x64 --output ./bin
        fi
      displayName: 'Build extensions'

    - task: SonarCloudPrepare@1
      inputs:
        SonarCloud: 'sonarcloud'
        organization: 'simnova'
        scannerMode: 'CLI'
        configMode: 'manual'
        cliProjectKey: 'sharethrift-data-access'
        cliProjectName: 'sharethrift-data-access'
        cliSources: './data-access'
        extraProperties: |
          sonar.javascript.lcov.reportPaths=$(System.DefaultWorkingDirectory)/data-access/coverage/lcov.info

    - task: Bash@3
      displayName: 'Prepare binaries'
      inputs:
        targetType: 'inline'
        script: |
          npm install
          npm run build:production
          npm run test:ci
        workingDirectory: 'data-access'

    - task: SonarCloudAnalyze@1
    - task: SonarCloudPublish@1
      inputs:
        pollingTimeoutSec: '300'      
      
    - task: ArchiveFiles@2
      displayName: 'Archive files'
      condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest'))
      inputs:
        rootFolderOrFile: '$(System.DefaultWorkingDirectory)/data-access'
        includeRootFolder: false
        archiveType: zip
        archiveFile: $(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip
        replaceExistingArchive: true

    - upload: $(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip
      condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest'))
      artifact: drop

- stage: Deploy
  displayName: Deploy stage
  dependsOn: Build
  condition: and(succeeded(), ne(variables['Build.Reason'], 'PullRequest'))
  jobs:
  - deployment: Deploy
    displayName: Deploy
    environment: $(environmentName)
    pool: 
      vmImage: $(vmImageName)
    strategy:
      runOnce:
        deploy:
          steps:            
          - task: AzureFunctionApp@1
            displayName: 'Azure Functions App Deploy: data-access'
            inputs:
              azureSubscription: 'ShareThrift'
              appType: functionAppLinux
              appName: $(functionAppName)
              package: '$(Pipeline.Workspace)/drop/$(Build.BuildId).zip'
              deploymentMethod: 'runFromPackage'
              runtimeStack: 'NODE|14'
          - task: AzureFunctionApp@1
            displayName: 'Azure Functions App Deploy: data-access-west'
            inputs:
              azureSubscription: 'ShareThrift'
              appType: 'functionAppLinux'
              appName: 'data-access-west'
              package: '$(Pipeline.Workspace)/drop/$(Build.BuildId).zip'
              deploymentMethod: 'runFromPackage'
              runtimeStack: 'NODE|14'
